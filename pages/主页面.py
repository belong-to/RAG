import os
import pandas as pd
import streamlit as st
from langchain_community.vectorstores import Qdrant
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain.text_splitter import RecursiveCharacterTextSplitter
import json
import re
import warnings

# å¯¼å…¥æ–‡ä»¶ç®¡ç†æ¨¡å—
from modules.file_manager import get_all_uploaded_files, save_uploaded_files, clear_uploaded_files
# å¯¼å…¥å¢å¼ºæ£€ç´¢æ¨¡å—
from modules.enhanced_retrieval import enhanced_retrieval
# å¯¼å…¥æ¨¡å‹æ¥å£
from modules.model_interface import get_llm_model, get_embedding_model, load_api_keys
# å¯¼å…¥æœç´¢å¼•æ“æ¨¡å—
from modules.search_engine import get_search_engine, format_search_results

warnings.filterwarnings("ignore")

#-----------------------æ¨¡å‹å‡†å¤‡------------------------

# è¯»å–API Keyé…ç½®æ–‡ä»¶
api_keys = load_api_keys()

# å¤§æ¨¡å‹é…ç½®
llm1 = get_llm_model('DeepSeek', api_keys)
llm2 = get_llm_model('é˜¿é‡Œé€šä¹‰åƒé—®', api_keys)

# Embeddingé…ç½®
embedding1 = get_embedding_model('DeepSeek', api_keys)
embedding2 = get_embedding_model('é˜¿é‡Œé€šä¹‰åƒé—®', api_keys)

# -----------------------æ•°æ®è¯»å–ã€åˆ‡åˆ†ã€å‘é‡åŒ–å‡½æ•°------------------------

def load_document(file):
    '''
    å¯¼å…¥æ–‡æ¡£ï¼Œæ”¯æŒ PDF, DOCX and TXT æ–‡ä»¶
    :param file: æ–‡ä»¶è·¯å¾„
    :return: æ–‡æœ¬æ•°æ®
    '''
    name, extension = os.path.splitext(file)
    if extension == '.pdf':
        loader = PyPDFLoader(file)
        documents = loader.load()
    elif extension == '.docx':
        loader = Docx2txtLoader(file)
        documents = loader.load()
    elif extension == '.txt':
        try:
            loader = TextLoader(file, encoding='utf8')
            documents = loader.load()
        except:
            loader = TextLoader(file, encoding='gbk')
            documents = loader.load()
    else:
        st.error('ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œä»…æ”¯æŒPDFã€DOCXã€TXTæ–‡ä»¶')
        documents = ''
    # æ–‡æ¡£é¢„å¤„ç†
    if documents and len(documents) > 0:
        documents[0].page_content = re.sub(r'\n{2,}', '\n', documents[0].page_content)
        documents[0].page_content = re.sub(r'\t', '', documents[0].page_content)
    return documents


def create_embeddings(documents, embedding):
    '''
    æ–‡æ¡£å‘é‡åŒ–å’Œå­˜å‚¨
    :param documents: åˆ‡åˆ†å¥½çš„æ–‡æ¡£
    :param embedding: å‘é‡åŒ–æ¨¡å‹
    :return: å‘é‡åŒ–å­˜å‚¨çš„å¯¹è±¡
    '''
    vectorstore = Qdrant.from_documents(
        documents=documents,
        embedding=embedding,
        location=':memory:',
        collection_name='my_documents')
    return vectorstore


def chunk_data(data, file_name='a.txt', chunk_size=256, chunk_overlap=100):
    '''
    æ–‡æ¡£åˆ‡åˆ†
    :param data: å¾…åˆ‡åˆ†çš„æ–‡æ¡£
    :param file_name: æ–‡ä»¶å
    :param chunk_size: åˆ‡å—å¤§å°
    :param chunk_overlap: åˆ‡å—é‡å å¤§å°
    :return: åˆ‡åˆ†åçš„æ–‡æ¡£å¯¹è±¡
    '''
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    chunks = text_splitter.split_documents(data)
    file_name = file_name.split('.')[0] # å»é™¤æ–‡ä»¶ååç¼€
    for i in chunks: # ç»™æ¯ä¸ªåˆ†å—æ·»åŠ å¯¹äºçš„æ¥æºæ–‡ä»¶åï¼Œä¾¿äºæ£€ç´¢æ›´ç²¾ç¡®
        i.page_content = file_name+'ã€‚'+i.page_content
    return chunks


# æ¸…ç©ºå¯¹è¯è®°å½•
def clear_chat_history():
    '''
    æ¸…ç©ºå¯¹è¯è®°å½•
    :return:
    '''
    if 'messages' in st.session_state:
        del st.session_state['messages']

def clear_embedding():
    '''
    æ¸…ç©ºçŸ¥è¯†åº“å’Œæ–‡æ¡£
    :return:
    '''
    for i in st.session_state.filenames: # åˆ é™¤ä¿å­˜çš„æ–‡ä»¶
        try:
            delfile = os.path.join('./uploads', i)
            os.remove(delfile)
        except:
            pass
    st.session_state.vs = [] # æ¸…ç©ºå‘é‡
    st.session_state.filenames = [] # æ¸…ç©ºä¿å­˜çš„æ–‡ä»¶å
    st.info('çŸ¥è¯†åº“å·²æ¸…ç©ºï¼Œå¯ä»¥æ–°å¢çŸ¥è¯†åº“åç»§ç»­ã€‚')
    global file_name
    try:
        del file_name # åˆ é™¤æ–‡ä»¶åå˜é‡
    except:
        pass

def convert_df():
    '''
    å°†å¯¹è¯è®°å½•è½¬æ¢ä¸ºcsvæ–‡ä»¶
    :return:
    '''
    df = pd.DataFrame(st.session_state.messages)
    df = df.applymap(lambda x: str(x).replace('\n', '').replace(',', 'ï¼Œ'))
    return df.to_csv(index=False, encoding='utf-8', mode='w', sep=',')

# -------------------------ä¸»é¡µé¢è®¾ç½®------------------------

st.set_page_config(page_title='å¢å¼ºå‹RAGæ–‡æ¡£æ£€ç´¢ç³»ç»Ÿ', page_icon=':robot:', layout='wide')

# åŠ è½½è‡ªå®šä¹‰CSS
try:
    # åŠ è½½å¢å¼ºæ ·å¼
    css_path = os.path.join(os.path.dirname(__file__), 'style_enhanced.css')
    with open(css_path, encoding='utf-8') as f:
        css_content = f.read()
        st.markdown(f'<style>{css_content}</style>', unsafe_allow_html=True)
    
    # åŠ è½½æ–°çš„å¢å¼ºUIæ ·å¼
    enhanced_css_path = os.path.join(os.path.dirname(__file__), 'enhanced_ui.css')
    with open(enhanced_css_path, encoding='utf-8') as f:
        enhanced_css_content = f.read()
        st.markdown(f'<style>{enhanced_css_content}</style>', unsafe_allow_html=True)
    
    # åŠ è½½åŠ¨ç”»æ ·å¼
    animations_css_path = os.path.join(os.path.dirname(__file__), 'animations.css')
    with open(animations_css_path, encoding='utf-8') as f:
        animations_css_content = f.read()
        st.markdown(f'<style>{animations_css_content}</style>', unsafe_allow_html=True)
except UnicodeDecodeError:
    css_path = os.path.join(os.path.dirname(__file__), 'style_enhanced.css')
    with open(css_path, encoding='latin-1') as f:
        css_content = f.read()
        st.markdown(f'<style>{css_content}</style>', unsafe_allow_html=True)

# åŠ è½½JavaScriptæ–‡ä»¶
try:
    # åŠ è½½ä¸»é¢˜åˆ‡æ¢JavaScript
    js_path = os.path.join(os.path.dirname(__file__), 'theme_switcher.js')
    with open(js_path, encoding='utf-8') as f:
        js_content = f.read()
        st.markdown(f'<script>{js_content}</script>', unsafe_allow_html=True)
    
    # åŠ è½½åŠ¨ç”»JavaScript
    animations_js_path = os.path.join(os.path.dirname(__file__), 'animations.js')
    with open(animations_js_path, encoding='utf-8') as f:
        animations_js_content = f.read()
        st.markdown(f'<script>{animations_js_content}</script>', unsafe_allow_html=True)
    
    # åŠ è½½UIå¢å¼ºJavaScript
    ui_enhancer_js_path = os.path.join(os.path.dirname(__file__), 'ui_enhancer.js')
    with open(ui_enhancer_js_path, encoding='utf-8') as f:
        ui_enhancer_js_content = f.read()
        st.markdown(f'<script>{ui_enhancer_js_content}</script>', unsafe_allow_html=True)
except Exception as e:
    st.error(f'åŠ è½½JavaScriptè„šæœ¬å¤±è´¥: {e}')

# æ·»åŠ å¡ç‰‡å®¹å™¨ç±»
st.markdown('<div class="card-container">', unsafe_allow_html=True)
    
st.markdown("<h1 class='main-title'>å¢å¼ºå‹RAGæ–‡æ¡£æ£€ç´¢ç³»ç»Ÿ <span class='emoji-title'>ğŸ¤–</span></h1>", unsafe_allow_html=True)
st.markdown('<div class="gradient-line"></div>', unsafe_allow_html=True)

# åˆå§‹åŒ–èŠå¤©è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = []

#  åˆå§‹åŒ–çŸ¥è¯†åº“
if "vs" not in st.session_state:
    st.session_state.vs = []

#  åˆå§‹åŒ–å¯¼å…¥çš„æ–‡ä»¶å
if "filenames" not in st.session_state:
    st.session_state.filenames = []

# åˆå§‹åŒ–æœç´¢å¼•æ“è®¾ç½®
if "use_web_search" not in st.session_state:
    st.session_state.use_web_search = False

if "search_engine" not in st.session_state:
    st.session_state.search_engine = "Mock"

if st.session_state.filenames == [] and not st.session_state.use_web_search:
    st.warning("æ‚¨è¿˜æ²¡æœ‰æ·»åŠ çŸ¥è¯†åº“æˆ–å¯ç”¨ç½‘ç»œæœç´¢ï¼Œæ¨¡å‹çš„å›ç­”å°†åŸºäºé€šç”¨çŸ¥è¯†ã€‚")

# å±•ç¤ºèŠå¤©è®°å½•
st.markdown("<div class='chat-container glass-effect'>", unsafe_allow_html=True)
if st.session_state.messages:
    for message in st.session_state.messages:
        if message["role"] == "user":
            with st.chat_message(message["role"], avatar='ğŸ‘¤'):
                st.markdown(message["content"])
        else:
            with st.chat_message(message["role"], avatar='ğŸ¤–'):
                st.markdown(message["content"])
else:
    st.markdown("<div class='empty-chat-message'>è¯·åœ¨ä¸‹æ–¹è¾“å…¥æ‚¨çš„é—®é¢˜å¼€å§‹å¯¹è¯...</div>", unsafe_allow_html=True)
st.markdown("</div>", unsafe_allow_html=True)

# å…³é—­å¡ç‰‡å®¹å™¨
st.markdown('</div>', unsafe_allow_html=True)


# ---------------------ä¾§è¾¹æ è®¾ç½®-----------------------

# åˆå§‹åŒ–ç™»å½•çŠ¶æ€
if 'logged_in' not in st.session_state:
    st.session_state.logged_in = True
if 'username' not in st.session_state:
    st.session_state.username = ""

# é€€å‡ºç™»å½•å‡½æ•°
def logout():
    st.session_state.logged_in = False
    st.session_state.username = ""
    st.session_state.page = "login"  # ç¡®ä¿é¡µé¢çŠ¶æ€è¢«é‡ç½®
    # é‡å®šå‘åˆ°ç™»å½•é¡µé¢
    st.markdown(f'''
    <meta http-equiv="refresh" content="0;url=http://localhost:8501">
    ''', unsafe_allow_html=True)
    st.stop()

# æ·»åŠ é€€å‡ºç™»å½•æŒ‰é’®
st.sidebar.markdown("<div class='sidebar-section'>", unsafe_allow_html=True)
st.sidebar.markdown("<h3>ğŸ‘¤ ç”¨æˆ·æ“ä½œ</h3>", unsafe_allow_html=True)
if st.sidebar.button("é€€å‡ºç™»å½•", use_container_width=True):
    logout()

# æ–‡æ¡£ä¸Šä¼ 
st.sidebar.markdown("<div class='sidebar-section'>", unsafe_allow_html=True)
st.sidebar.markdown("<h3>ğŸ“ ä¸Šä¼ çŸ¥è¯†åº“</h3>", unsafe_allow_html=True)
uploaded_files = st.sidebar.file_uploader('æ–‡ä»¶ä¸Šä¼ :', type=['pdf', 'docx', 'txt', 'doc'], accept_multiple_files=True, help="æ”¯æŒPDFã€DOCXã€TXTæ–‡ä»¶æ ¼å¼")

if not uploaded_files:
    # æ£€æŸ¥uploadsæ–‡ä»¶å¤¹ä¸­æ˜¯å¦å·²æœ‰æ–‡ä»¶
    existing_files = get_all_uploaded_files()
    if existing_files:
        st.sidebar.success(f'å·²æœ‰{len(existing_files)}ä¸ªæ–‡ä»¶åœ¨çŸ¥è¯†åº“ä¸­ï¼Œå¯ç›´æ¥ã€æ·»åŠ çŸ¥è¯†åº“ã€‘')
else:
    st.sidebar.warning(f'ä¸Šä¼ æˆåŠŸï¼å…±{len(uploaded_files)}ä¸ªæ–‡ä»¶ï¼Œæ³¨æ„ã€æ·»åŠ çŸ¥è¯†åº“ã€‘')

# åˆ†å—å‚æ•°
st.sidebar.markdown("<div class='sidebar-section'>", unsafe_allow_html=True)
st.sidebar.markdown("<h3>âš™ï¸ å‚æ•°è®¾ç½®</h3>", unsafe_allow_html=True)
chunk_size = st.sidebar.slider('ğŸ“„ åˆ†å—å¤§å°', min_value=100, max_value=2048, value=1024, step=50, help="è¾ƒå¤§çš„åˆ†å—å¤§å°å¯èƒ½åŒ…å«æ›´å¤šä¸Šä¸‹æ–‡ï¼Œä½†å¯èƒ½é™ä½æ£€ç´¢ç²¾åº¦")
st.sidebar.caption(f"å½“å‰åˆ†å—å¤§å°: {chunk_size} å­—ç¬¦")

# æœç´¢æ–‡æ¡£å‚æ•°
k = st.sidebar.slider('ğŸ” æœç´¢è¿”å›æ–‡æ¡£æ•°', min_value=1, max_value=100, value=10, step=1, help="å¢åŠ è¿”å›æ–‡æ¡£æ•°å¯èƒ½æé«˜å¬å›ç‡ï¼Œä½†å¯èƒ½é™ä½ç²¾ç¡®åº¦")
st.sidebar.caption(f"å½“å‰è¿”å›æ–‡æ¡£æ•°: {k} ä¸ª")

# æ¨¡å‹é€‰æ‹©å‚æ•°
myllm = st.sidebar.selectbox('æ¨¡å‹é€‰æ‹©', ['é˜¿é‡Œé€šä¹‰åƒé—®', 'DeepSeek'], help="é€‰æ‹©ä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹å¯èƒ½ä¼šå½±å“å›ç­”è´¨é‡å’Œé£æ ¼")
st.sidebar.markdown("</div>", unsafe_allow_html=True)

# æ ¹æ®é€‰æ‹©çš„æ¨¡å‹ï¼Œæ·»åŠ å¯¹åº”çš„Embeddingæ¨¡å‹
if myllm == 'DeepSeek':
    llm = llm1
    embedding = embedding1
elif myllm == 'é˜¿é‡Œé€šä¹‰åƒé—®':
    llm = llm2
    embedding = embedding2
else:
    pass

# çŸ¥è¯†åº“ç®¡ç†å‚æ•°
st.sidebar.markdown("<div class='sidebar-section'>", unsafe_allow_html=True)
st.sidebar.markdown("<h3>ğŸ“š çŸ¥è¯†åº“ç®¡ç†</h3>", unsafe_allow_html=True)
add_or_no = st.sidebar.radio('çŸ¥è¯†åº“ç®¡ç†', ['åˆå¹¶æ–°å¢çŸ¥è¯†åº“', 'ä»…ä½¿ç”¨å½“å‰çŸ¥è¯†åº“'], help="é€‰æ‹©æ˜¯å¦ä¿ç•™ä¹‹å‰çš„çŸ¥è¯†åº“")
st.sidebar.markdown("</div>", unsafe_allow_html=True)

# æœç´¢å¼•æ“è®¾ç½®
st.sidebar.markdown("<div class='sidebar-section'>", unsafe_allow_html=True)
st.sidebar.markdown("<h3>ğŸ” æœç´¢å¼•æ“è®¾ç½®</h3>", unsafe_allow_html=True)
st.session_state.use_web_search = st.sidebar.checkbox('å¯ç”¨ç½‘ç»œæœç´¢', value=st.session_state.use_web_search, help="å¯ç”¨åå¯ä»¥ä»äº’è”ç½‘è·å–ä¿¡æ¯")

if st.session_state.use_web_search:
    st.session_state.search_engine = st.sidebar.selectbox(
        'é€‰æ‹©æœç´¢å¼•æ“', 
        ['Mock', 'SerpApi', 'Bing'],
        index=['Mock', 'SerpApi', 'Bing'].index(st.session_state.search_engine),
        help="Mockä¸ºæ¨¡æ‹Ÿæœç´¢ï¼ŒSerpApiå’ŒBingéœ€è¦APIå¯†é’¥"
    )
    
    num_web_results = st.sidebar.slider('ç½‘ç»œæœç´¢ç»“æœæ•°é‡', min_value=1, max_value=10, value=3, help="å¢åŠ ç»“æœæ•°é‡å¯èƒ½æä¾›æ›´å¤šä¿¡æ¯ï¼Œä½†å¯èƒ½å¢åŠ å¤„ç†æ—¶é—´")
    st.sidebar.markdown("</div>", unsafe_allow_html=True)
    
    # å¦‚æœé€‰æ‹©äº†çœŸå®æœç´¢å¼•æ“ï¼Œæ˜¾ç¤ºAPIå¯†é’¥é…ç½®
    if st.session_state.search_engine != 'Mock':
        with st.sidebar.expander("æœç´¢å¼•æ“APIé…ç½®"):
            if st.session_state.search_engine == 'SerpApi':
                serpapi_key = st.text_input("SerpApi Key", type="password")
                if serpapi_key:
                    api_keys['serpapi'] = serpapi_key
            elif st.session_state.search_engine == 'Bing':
                bing_key = st.text_input("Bing API Key", type="password")
                if bing_key:
                    api_keys['bing'] = bing_key

# ç‚¹å‡»å¯¼å…¥æ–‡ä»¶åï¼Œå°†æ–‡ä»¶å†…å®¹å†™å…¥æœ¬åœ°
if uploaded_files:  # if the user browsed files
    with st.spinner('æ­£åœ¨è¯»å–æ–‡ä»¶ ...'):
        # æ¸…ç†æ–‡ä»¶åˆ—è¡¨
        if add_or_no == 'ä»…ä½¿ç”¨å½“å‰çŸ¥è¯†åº“':
            # æ¸…ç©ºä¹‹å‰çš„æ–‡ä»¶è®°å½•
            st.session_state.filenames = []
            # æ¸…ç©ºuploadsæ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶
            clear_uploaded_files(st.session_state.filenames)
            
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        saved_files = save_uploaded_files(uploaded_files)
        st.session_state.filenames.extend(saved_files)

# ---------------------å¯¹è¯æ å¯¹è¯è®¾ç½®-----------------------

if prompt := st.chat_input('è¯·è¾“å…¥ä½ çš„é—®é¢˜'):
    # è¾“å…¥é—®é¢˜
    with st.chat_message('user', avatar='â˜ºï¸'):
        st.markdown(prompt)
    # åœ¨å†å²å¯¹è¯ä¸­æ·»åŠ ç”¨æˆ·çš„é—®é¢˜
    st.session_state.messages.append({'role': 'user', 'content': prompt})
    
    # è°ƒç”¨å¢å¼ºæ£€ç´¢å‡½æ•°ï¼Œè·å–å›ç­”
    with st.spinner('æ­£åœ¨æ£€ç´¢ï¼Œè¯·ç¨å ...'):
        response = enhanced_retrieval(
            llm=llm, 
            query=prompt, 
            vector_store=st.session_state.vs, 
            search_engine_name=st.session_state.search_engine if st.session_state.use_web_search else None,
            use_web_search=st.session_state.use_web_search,
            k=k,
            num_web_results=num_web_results if st.session_state.use_web_search else 0
        )
    
    # è¾“å‡ºç­”æ¡ˆ
    with st.chat_message('AI', avatar='ğŸ¤–'):
        st.markdown(response)
    # åœ¨å†å²å¯¹è¯ä¸­æ·»åŠ é—®é¢˜çš„ç­”æ¡ˆ
    st.session_state.messages.append({'role': 'AI', 'content': response})


# ---------------------å¯¹è¯æ æ¸…ç©ºå¯¹è¯ã€å¯¼å…¥çŸ¥è¯†åº“ç­‰è®¾ç½®-----------------------
st.markdown("<div class='action-buttons-container'>", unsafe_allow_html=True)
st.markdown("<h3 class='action-title'>æ“ä½œé¢æ¿</h3>", unsafe_allow_html=True)
col1, col2, col3, col4 = st.columns([1, 1, 1, 1])

with col1:
    add = st.button('æ·»åŠ çŸ¥è¯†åº“ ğŸ“š', use_container_width=True)

with col2:
    drop_embedding = st.button('æ¸…ç©ºçŸ¥è¯†åº“ ğŸ—‘ï¸', use_container_width=True)
if drop_embedding:
    clear_embedding()
    st.toast(':red[çŸ¥è¯†åº“å·²æ¸…ç©ºï¼]', icon='ğŸ¤–')

with col3:
    if st.button("æ¸…é™¤å¯¹è¯å†å² ğŸ”„", on_click=clear_chat_history, use_container_width = True):
        st.session_state["messages"] = []
        st.toast(':red[å¯¹è¯å†å²å·²æ¸…é™¤ï¼]', icon='ğŸ¤–')

with col4:
    download_button = st.download_button(label="å¯¼å‡ºå¯¹è¯è®°å½• ğŸ“¥",
                                         data=convert_df(), # å¯¼å‡ºå‡½æ•°
                                         file_name='chat_history.csv', # æ–‡ä»¶å
                                         mime='text/csv',  # æ–‡ä»¶ç±»å‹
                                         use_container_width=True)
st.markdown("</div>", unsafe_allow_html=True)

# å…³é—­å¡ç‰‡å®¹å™¨
st.markdown('</div>', unsafe_allow_html=True)
if add:
    with st.spinner("çŸ¥è¯†åº“ç”Ÿæˆä¸­..."):
        # æ¸…ç©ºç°æœ‰çŸ¥è¯†åº“ï¼ˆå¦‚æœé€‰æ‹©äº†ä»…ä½¿ç”¨å½“å‰çŸ¥è¯†åº“ï¼‰
        if add_or_no == 'ä»…ä½¿ç”¨å½“å‰çŸ¥è¯†åº“':
            st.session_state.vs = []
            
        # è·å–æ‰€æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶
        all_files = []
        if st.session_state.filenames:  # å¦‚æœæœ‰é€šè¿‡ä¸Šä¼ ç»„ä»¶ä¸Šä¼ çš„æ–‡ä»¶
            all_files = [os.path.join('./uploads', file_name) for file_name in st.session_state.filenames]
        else:  # å¦åˆ™è·å–uploadsæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
            all_files = get_all_uploaded_files()
            # æ›´æ–°æ–‡ä»¶ååˆ—è¡¨
            st.session_state.filenames = [os.path.basename(file_path) for file_path in all_files]
            
        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        all_chunks = []
        for file_path in all_files:
            # è¯»å–æ–‡æ¡£
            data = load_document(file_path)
            # åˆ†å‰²æ•°æ®
            file_name = os.path.basename(file_path)
            chunks = chunk_data(data, file_name=file_name, chunk_size=chunk_size)
            all_chunks.extend(chunks)
            
        # åˆ›å»ºçŸ¥è¯†åº“çš„åµŒå…¥å‘é‡
        if all_chunks:
            vector_store = create_embeddings(all_chunks, embedding)
            st.toast(':red[çŸ¥è¯†åº“æ·»åŠ æˆåŠŸï¼]', icon='ğŸ¤–')
            
            # ä¿å­˜çŸ¥è¯†åº“
            if add_or_no == 'åˆå¹¶æ–°å¢çŸ¥è¯†åº“' and st.session_state.vs != []:
                st.session_state.vs.add_documents(all_chunks)  # æ·»åŠ æ–°çš„æ–‡æ¡£
            else:
                st.session_state.vs = vector_store
                
            # æ·»åŠ çŸ¥è¯†åº“åç§°
            files = 'ï¼›'.join(list(set(st.session_state.filenames)))
            st.success(f'æ·»åŠ æˆåŠŸï¼å·²æœ‰çŸ¥è¯†åº“ï¼š{files}')
            if st.session_state.messages == []:
                st.session_state.messages.append({'role': 'AI', 'content': f'å·²æœ‰çŸ¥è¯†åº“ï¼š{files}'})
            else:
                st.session_state.messages[-1] = {'role': 'AI', 'content': f'å·²æœ‰çŸ¥è¯†åº“ï¼š{files}'}
            with st.chat_message('AI', avatar='ğŸ¤–'):
                st.markdown(st.session_state.messages[-1]['content'])